{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from math import sqrt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3)\n",
    "fig_width = 6.9\n",
    "golden_mean = (sqrt(5)-1.0)/2.0    # Aesthetic ratio\n",
    "fig_height = fig_width*golden_mean # height in inches\n",
    "\n",
    "params = {\n",
    "   'axes.labelsize': 8,\n",
    "   'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "   'font.size': 10,\n",
    "    'axes.labelsize': 10, # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize': 12,\n",
    "   'legend.fontsize': 8,\n",
    "   'xtick.labelsize': 10,\n",
    "   'ytick.labelsize': 10,\n",
    "   'text.usetex': True,\n",
    "   'figure.figsize': [fig_width,fig_height],\n",
    "    'font.family': 'serif'\n",
    "   }\n",
    "rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this post I will show you step by step how to create a machine learning experiment with  Scikit-learn that allows you to predict whether you or your friends would have survived the sinking of the titanic!.\n",
    "\n",
    "\n",
    "This recipe is based on a [Kaggle competition](https://www.kaggle.com/c/titanic) where the goal is to predict survival on the Titanic, based on real data. [Kaggle](https://www.kaggle.com/competitions) hosts machine learning competitions where anyone can download a dataset, train a model, and test the predictions on the website. The author of the best model wins a price. It is a fun way to get started with machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data =pd.read_csv('Data/Titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn will expect numeric values and no blanks, so first we need to do a bit more wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Sex' is stored as a text value. We should convert (or 'map') it into numeric binaries \n",
    "# so it will be ready for scikit-learn.\n",
    "data['Sex'] = data['Sex'].map({'male': 0,'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's also drop the 'Cabin','Embarked' 'Ticket' and 'Name' columns\n",
    "data = data.drop(['Cabin'], axis=1)\n",
    "data = data.drop(['Embarked'], axis=1)\n",
    "data = data.drop(['Name'], axis=1)\n",
    "data = data.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle missing data\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrange data into a features matrix and target vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "X = data[features]\n",
    "y = data.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate Some Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to create some models of the data and estimate their accuracy on unseen data.\n",
    "\n",
    "Here is what we are going to cover in this step:\n",
    "\n",
    "* Separate out a validation dataset.\n",
    "* Set-up the test harness to use 10-fold cross validation.\n",
    "* Build 5 different models to predict species from flower measurements\n",
    "* Select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Validation Dataset\n",
    "\n",
    "A better sense of a model's performance can be found using what's known as a holdout set: that is, we hold back some subset of the data from the training of the model, and then use this holdout set to check the model performance. This splitting can be done using the train_test_split utility in Scikit-Learn. We will split the loaded dataset into two, 80% of which we will use to train our models and 20% that we will hold back as a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the data with 20% in each set\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the metric of ‘accuracy‘ to evaluate models. This is a ratio of the number of correctly predicted instances in divided by the total number of instances in the dataset multiplied by 100 to give a percentage (e.g. 95% accurate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Models\n",
    "\n",
    "We don’t know which algorithms would be good on this problem or what configurations to use. We get an idea from the plots that some of the classes are partially linearly separable in some dimensions, so we are expecting generally good results.\n",
    "\n",
    "Let’s evaluate 4 different algorithms:\n",
    "\n",
    "* Logistic Regression (LR)\n",
    "* K-Nearest Neighbors (KNN).\n",
    "* Random Forest\n",
    "* Gaussian Naive Bayes (NB).\n",
    "* Support Vector Machines (SVM).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cross-validation\n",
    "\n",
    "In cross-validation, the data is instead split repeatedly and multiple models are trained.  The most commonly used version of cross-validation is **k-fold cross-validation**, where k is a user-specified number, usually 5 or 10. We will use 10-fold cross validation to estimate accuracy. This will split our dataset into 10 parts, train on 9 and test on 1 and repeat for all combinations of train-test splits.\n",
    "\n",
    "Cross-validation is implemented in scikit-learn using the **cross_val_score func‐\n",
    "tion** from the model_selection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "def classifiers(X_train,y_train):\n",
    "    knn = KNeighborsClassifier()\n",
    "    gnb = GaussianNB()\n",
    "    logistic = LogisticRegression()\n",
    "    svc = svm.SVC()\n",
    "    dTree = tree.DecisionTreeClassifier()\n",
    "    rForest = RandomForestClassifier()\n",
    "    \n",
    "    \n",
    "    names = [\"Nearest Neighbors\", \"Naive Bayes\",\"Logistic\",\"RBF SVM\",\"Decision Tree\",\"Random Forest\"]\n",
    "    models = [knn, gnb, logistic, svc, dTree, rForest]\n",
    "    \n",
    "    name= []\n",
    "    results=[]\n",
    "    for (i,model) in enumerate(models):\n",
    "        kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "        cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        msg = \"%s: %f\" % (names[i], cv_results.mean())\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it looks like Random Forest has the largest estimated accuracy score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest algorithm was the most accurate model that we tested. Now we want to get an idea of the accuracy of the model on our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression();\n",
    "logreg.fit(X_train, y_train)\n",
    "y_predicted = logreg.predict(X_test)\n",
    "print(\"Prediction accuracy: %f\" % logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rForest = RandomForestClassifier()\n",
    "rForest.fit(X_train, y_train) \n",
    "y_pred = rForest.predict(X_test)\n",
    "print(\"Prediction accuracy: %f\" % rForest.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "* Apply the learned concept on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
