{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from math import sqrt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3)\n",
    "fig_width = 6.9\n",
    "golden_mean = (sqrt(5)-1.0)/2.0    # Aesthetic ratio\n",
    "fig_height = fig_width*golden_mean # height in inches\n",
    "\n",
    "params = {\n",
    "   'axes.labelsize': 8,\n",
    "   'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "   'font.size': 10,\n",
    "    'axes.labelsize': 10, # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize': 12,\n",
    "   'legend.fontsize': 8,\n",
    "   'xtick.labelsize': 10,\n",
    "   'ytick.labelsize': 10,\n",
    "   'text.usetex': True,\n",
    "   'figure.figsize': [fig_width,fig_height],\n",
    "    'font.family': 'serif'\n",
    "   }\n",
    "rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Scikit-Learn\n",
    "\n",
    "\n",
    "We aims to give an accessible introduction to how to use machine learning techniques using [scikit-learn](http://scikit-learn.org/) for your own projects and datasets. Among the ML libraries available today, scikit-learn shines as one of the best options.\n",
    "\n",
    "[Scikit-learn](http://scikit-learn.org/) is a Python open source library designed to tackle Machine Learning problems from beginning to end. It is used and well praised by big companies like Evernote, Spotify etc as shown [here](http://scikit-learn.org/stable/testimonials/testimonials.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Representation in Scikit-Learn\n",
    "\n",
    "The best way to think about data within Scikit-Learn is in terms of tables of data. Consider the Cities data set below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/Cities.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here each row of the data refers to a single observed city, and the number of rows is the total number of city in the dataset. In general, we will refer to the rows of the matrix as samples, and the number of rows as $n_{samples}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, each column of the data refers to a particular quantitative piece of information that describes each sample. In general, we will refer to the columns of the matrix as features, and the number of columns as $n_{features}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features matrix\n",
    "\n",
    "A two-dimensional numerical array or matrix with shape [$n_{samples}$, $n_{features}$]. By convention, this features matrix is often stored in a variable named $X$.\n",
    "\n",
    "The samples (i.e., rows) always refer to the individual objects described by the dataset\n",
    "\n",
    "The features (i.e., columns) always refer to the distinct observations that describe each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target array\n",
    "\n",
    "One dimensional, with length $n_{samples}$ usually the quantity we want to predict from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn's Estimator API\n",
    "\n",
    "Every machine learning algorithm in Scikit-Learn is implemented via the Estimator API, which provides a consistent interface for a wide range of machine learning applications.\n",
    "\n",
    "The steps in using the Scikit-Learn estimator API are as follows:\n",
    "\n",
    "* Choose a class of model by importing the appropriate estimator class from Scikit-Learn.\n",
    "* Choose model hyperparameters by instantiating this class with desired values.\n",
    "   * Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments the estimator classes.\n",
    "* Arrange data into a features matrix and target vector following the discussion above.\n",
    "* Fit the model to your data by calling the **fit()** method of the model instance.\n",
    "* Apply the Model to new data:\n",
    "  * For supervised learning, often we predict labels for unknown data using the **predict()** method.\n",
    "  * For unsupervised learning, we often transform or infer properties of the data using the **transform()** or **predict()** method.\n",
    "  \n",
    "Let us apply this step in the following example  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning: Simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regression, we are interested in predicting a scalar-valued target, such as the price of a stock. By linear, we mean that the target must be predicted as a linear function of the inputs.\n",
    "\n",
    "We will use the Cities dataset and our target is to predict city temperature given its latitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Let Choose a class of model\n",
    "\n",
    "Import  the linear regression class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** more general linear regression models exist as well follow this [link](http://scikit-learn.org/stable/modules/linear_model.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose model hyperparameters\n",
    "\n",
    "This step involve defining the model with its associated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Arrange data into a features matrix and target vector\n",
    "\n",
    "Here our target variable y is already tempearture and the feature matrix is latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.uniform(0, 1, 100)\n",
    "y =  X*2 + np.random.randn(100) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the shape of target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We therefore need to massage the data X to make it a matrix of size [n_samples, n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  convert the 1-dimensional X  array into an X array with 2 axes\n",
    "X = X[:, np.newaxis]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit the model to your data\n",
    "\n",
    "Now it is time to apply our model to data. This can be done with the fit() method of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fit() command causes a number of model-dependent internal computations to take place, and the results of these computations are stored in model-specific attributes that the user can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Weight coefficients: ', model.coef_)\n",
    "print('y-axis intercept: ', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Predict labels for unknown data\n",
    "Once the model is trained, the main task of supervised machine learning is to evaluate it based on what it says about new data.\n",
    "\n",
    "For the sake of this example, our \"new data\" will be a grid of X values, and we will ask what y values the model predicts:\n",
    "\n",
    "Let select the last ten city and use our model to predict their temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xval = X[0:50]\n",
    "xval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we need to coerce these X values into a [n_samples, n_features] features matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let visulaize the actual values vs predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_actual = y[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_name = \"ML_regression\"\n",
    "plt.scatter(xval, y_actual, label=\"data\")\n",
    "plt.scatter(xval, y_pred, label=\"prediction\")\n",
    "plt.plot(xval,y_pred, c='red',label='fit')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Model Visualization')\n",
    "plt.xlabel('City Latitude')\n",
    "plt.ylabel('City Temperature')\n",
    "plt.savefig('image/%s.pdf' %(plot_name), format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning: Classification.\n",
    "\n",
    "Our question will be this: given a model trained on a portion of the player data, Predict player position from one or more of minutes, shots, passes, tackles, saves.\n",
    "\n",
    "For this task, we will use an extremely simple logistic regression.\n",
    "\n",
    "We would like to evaluate the model on data it has not seen before, and so we will split the data into a training set and a testing set. \n",
    "\n",
    "This could be done by hand, but it is more convenient to use the **train_test_split utility** function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/Players.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['minutes', 'shots', 'passes', 'tackles', 'saves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data[features]\n",
    "y = data.position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the dataset into to separate sets, using 75% of the instances for training our classifier, and the remaining 25% for evaluating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data arranged, we can follow our recipe to predict the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression   # 1. choose model class\n",
    "model = LogisticRegression()               # 2. instantiate model\n",
    "model.fit(X_train, y_train)                           # 3. fit model to data\n",
    "y_pred = model.predict(X_test)                        # 4. predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the accuracy_score utility to see the fraction of predicted labels that match their true value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus our model achieve a test accuracy of $61\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Classification¶\n",
    "\n",
    "First, we will look at a two class classification problem. Consider the case we want to predict whether a student with certain pass mark can be admitted or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admission = pd.read_csv('Data/admission.csv', names = [\"grade1\", \"grade2\", \"remark\"])\n",
    "admission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data is two-dimensional, we can plot each sample as a point in a two-dimensional coordinate system, with the first feature being the x-axis and the second feature being the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admitted_1 =admission[admission['remark']==1]['grade1']\n",
    "admitted_2 =admission[admission['remark']==1]['grade2']\n",
    "not_admitted_1 =admission[admission['remark']==0]['grade1']\n",
    "not_admitted_2 =admission[admission['remark']==0]['grade2']\n",
    "\n",
    "plot_name = \"scatter_1\"\n",
    "plt.scatter(admitted_1,admitted_2,c='green',s=10)\n",
    "plt.scatter(not_admitted_1,not_admitted_2,c='red',s=10)\n",
    "plt.xlabel('Grade 1')\n",
    "plt.ylabel('Grade 2')\n",
    "plt.legend(('Admitted','Not admitted'),scatterpoints=1,loc='upper right')\n",
    "plt.savefig('image/%s.pdf' %(plot_name), format='pdf')          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a supervised task, and since we are interested in its performance on unseen data, we split our data into two parts:\n",
    "\n",
    "* a training set that the learning algorithm uses to fit the model\n",
    "* a test set to evaluate the generalization performance of the model\n",
    "\n",
    "The train_test_split function from the model_selection module does that for us -- we will use it to split a dataset into 75% training data and 25% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['grade1', 'grade2']\n",
    "X = admission[features]\n",
    "y = admission.remark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression   # 1. choose model class\n",
    "model = LogisticRegression()               # 2. instantiate model\n",
    "model.fit(X_train, y_train)                           # 3. fit model to data\n",
    "y_pred = model.predict(X_test)                        # 4. predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate our classifier quantitatively by measuring what fraction of predictions is correct. This is called accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It clear that our model achieve a test accuracy of $95.99\\%$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a convenience function , score, that all scikit-learn classifiers have to compute this directly from the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression is a so-called linear model, that means it will create a decision that is linear in the input space. In 2d, this simply means it finds a line to separate the blue from the red:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another classifier: K Nearest Neighbors¶\n",
    "Another popular and easy to understand classifier is K nearest neighbors (kNN). It has one of the simplest learning strategies: given a new, unknown observation, look up in your reference database which ones have the closest features and assign the predominant class.\n",
    "\n",
    "The interface is exactly the same as for LogisticRegression above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining the model with its associated parameters\n",
    "from sklearn.neighbors import KNeighborsClassifier   # 1. choose model class\n",
    "knn = KNeighborsClassifier(n_neighbors=1)               # 2. instantiate model\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)                        # 4. predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise¶\n",
    "Apply the KNeighborsClassifier to the player dataset. Play with different values of the n_neighbors and observe how training and test score change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another classifier:  RANDOM FOREST¶\n",
    "\n",
    "A random forest is a 'meta estimator'. It will fit a number of decision trees (we'll have to tell it how many) on various sub-samples of the dataset. Then it will use averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rForest = RandomForestClassifier(n_estimators=10)\n",
    "rForest.fit(X_train, y_train) \n",
    "y_pred = rForest.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rForest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise¶\n",
    "Apply the Random Forest to the player dataset. Play with different values of the n_estimators and observe how training and test score change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Supervised Learning: Regression Analysis\n",
    "\n",
    "In regression we are trying to predict a continuous output variable -- in contrast to the nominal variables we were predicting in the previous classification examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/Cities.csv')\n",
    "X = data.latitude\n",
    "X = X[:, np.newaxis]\n",
    "y = data.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the learning algorithm implemented in LinearRegression to fit a regression model to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting to the training data, we paramerterized a linear regression model with the following values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Weight coefficients: ', regressor.coef_)\n",
    "print('y-axis intercept: ', regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the estimators for classification in the previous notebook, we use the predict method to predict the target variable. And we expect these predicted values to fall onto the line that we plotted previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_train = regressor.predict(X_train)\n",
    "plt.plot(X_train, y_train, 'o', label=\"data\")\n",
    "plt.plot(X_train, y_pred_train, 'o', label=\"prediction\")\n",
    "plt.plot([X.min(), X.max()], [min_pt, max_pt], label='fit')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides an easy way to evaluate the prediction quantitatively using the score method. For regression tasks, this is the R2 score (cost). Another popular way would be the Mean Squared Error (MSE). As its name implies, the MSE is simply the average squared difference over the predicted and actual target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regressor.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop asking user for city name, compute predicted + actual temperature\n",
    "while True:\n",
    "    name = input('Enter city name (or \"quit\" to quit): ')\n",
    "    if name == 'quit': break\n",
    "    city = data[data.city == name]\n",
    "    if len(city) == 0:\n",
    "        print ('City not in dataset')\n",
    "    else:\n",
    "        # Use float() to convert dataframe element to value\n",
    "        print ('Predicted temperature:', regressor.coef_[0] * float(city.latitude) + regressor.intercept_)\n",
    "        print ('Actual temperature:', float(city.temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "* From the players data, compute and plot a linear regression for minutes played (x-axis) versus passes made (y-axis).\n",
    "* Use linear regression for interactive number-of-passes predictor: compute minutes-passes regression for players from Greece, USA, and Portugal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### KNeighborsRegression\n",
    "As for classification, we can also use a neighbor based method for regression. We can simply take the output of the nearest point, or we could average several nearest points. This method is less popular for regression than for classification, but still a good baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "kneighbor_regression = KNeighborsRegressor(n_neighbors=1)\n",
    "kneighbor_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Let us look at the behavior on training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_test = kneighbor_regression.predict(X_test)\n",
    "\n",
    "plt.plot(X_test, y_test, 'o', label=\"data\", markersize=8)\n",
    "plt.plot(X_test, y_pred_test, 's', label=\"prediction\", markersize=4)\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kneighbor_regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop asking user for city name, compute predicted + actual temperature\n",
    "while True:\n",
    "    name = input('Enter city name (or \"quit\" to quit): ')\n",
    "    if name == 'quit': break\n",
    "    city = data[data.city == name]\n",
    "    if len(city) == 0:\n",
    "        print ('City not in dataset')\n",
    "    else:\n",
    "        # Use float() to convert dataframe element to value\n",
    "        temp_pred = kneighbor_regression.predict(city.latitude))\n",
    "        print ('Predicted temperature:', temp_pred[0])\n",
    "        print ('Actual temperature:', float(city.temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Introduction to Machine Learning in Python with scikit-learn](http://ipython-books.github.io/featured-04/)\n",
    "* [Introduction to Machine Learning with Python](https://github.com/amueller/introduction_to_ml_with_python)\n",
    "* [Scikit-learn tutorial at SciPy2016](https://github.com/amueller/scipy-2016-sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
